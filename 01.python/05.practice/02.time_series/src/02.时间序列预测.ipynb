{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50240e3c-d68f-4a17-827d-958d70cf734f",
   "metadata": {},
   "source": [
    "# åŸºäºæœºå™¨å­¦ä¹ çš„æ—¶é—´åºåˆ—é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c65df0a-ede2-4a01-91af-d038094a3123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:26:42.125023Z",
     "start_time": "2024-10-17T10:26:42.116428Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from math import sqrt\n",
    "import joblib\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "from collections import UserDict\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾SimHei\n",
    "plt.rcParams['axes.unicode_minus'] = False # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "np.set_printoptions(precision=2)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319505c",
   "metadata": {},
   "source": [
    "## å¯ç”¨æ¨¡å‹ä»‹ç»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78eda8b",
   "metadata": {},
   "source": [
    "ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ ç®—æ³•åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¡¨ç°ä¸é”™çš„æœ‰ä»¥ä¸‹å‡ ç§ï¼š\n",
    "\n",
    "1. çº¿æ€§å›å½’ (Linear Regression)  \n",
    "é€šè¿‡å»ºç«‹è¾“å…¥ç‰¹å¾å’Œç›®æ ‡å˜é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»æ¥è¿›è¡Œé¢„æµ‹ã€‚é€‚ç”¨äºç®€å•çš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œä½†æ˜¯å¯¹éçº¿æ€§å’Œå¤æ‚æ¨¡å¼çš„å¤„ç†èƒ½åŠ›æœ‰é™ã€‚\n",
    "2. å†³ç­–æ ‘ (Decision Tree)  \n",
    "å†³ç­–æ ‘é€šè¿‡æ„å»ºç‰¹å¾çš„åˆ†å±‚å†³ç­–è§„åˆ™æ¥åšé¢„æµ‹ã€‚å®ƒå¯ä»¥å¤„ç†éçº¿æ€§å…³ç³»å’Œå¤æ‚çš„æ¨¡å¼ï¼Œä¸è¿‡å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆã€‚\n",
    "3. éšæœºæ£®æ— (Random Forest)  \n",
    "éšæœºæ£®æ—æ˜¯å¤šæ£µå†³ç­–æ ‘çš„é›†åˆï¼Œä½¿ç”¨é›†æˆå­¦ä¹ çš„æ€æƒ³æ¥æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œç¨³å¥æ€§ã€‚å®ƒå¯ä»¥å¾ˆå¥½åœ°å¤„ç†æ—¶é—´åºåˆ—çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯å¸¦æœ‰éçº¿æ€§ç‰¹å¾çš„æ•°æ®ã€‚\n",
    "4. æ”¯æŒå‘é‡æœº (Support Vector Machine, SVM)  \n",
    "SVM åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å¯ä»¥ç”¨äºå›å½’ï¼ˆç§°ä¸ºæ”¯æŒå‘é‡å›å½’ï¼ŒSVRï¼‰ã€‚å®ƒé€‚åˆç”¨äºå¤æ‚çš„éçº¿æ€§æ¨¡å¼ï¼Œä½†åœ¨é«˜ç»´æ•°æ®ä¸Šçš„è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚\n",
    "5. K-è¿‘é‚»ç®—æ³• (K-Nearest Neighbors, KNN)  \n",
    "KNN å›å½’å¯ä»¥ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚å®ƒçš„åŸç†æ˜¯åŸºäºç›¸ä¼¼çš„å†å²æ•°æ®ç‚¹æ¥é¢„æµ‹æœªæ¥å€¼ï¼Œé€‚ç”¨äºæ¨¡å¼é‡å¤æ€§å¼ºçš„æ—¶é—´åºåˆ—ã€‚\n",
    "6. XGBoost/LightGBM  \n",
    "è¿™äº›æ˜¯åŸºäºæ¢¯åº¦æå‡å†³ç­–æ ‘ (GBDT) çš„é›†æˆç®—æ³•ï¼Œè¿‘å¹´æ¥åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­éå¸¸å—æ¬¢è¿ã€‚å®ƒä»¬å¯ä»¥æ•æ‰åˆ°éçº¿æ€§å…³ç³»ï¼Œå¹¶èƒ½å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ã€‚  \n",
    "\n",
    "ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨å¾€å¾€éœ€è¦å°†æ—¶é—´åºåˆ—æ•°æ®è½¬æ¢ä¸ºç›‘ç£å­¦ä¹ çš„å½¢å¼ï¼ˆä¾‹å¦‚ä½¿ç”¨æ»åå€¼ä½œä¸ºç‰¹å¾ï¼‰ï¼Œæ‰èƒ½æ›´å¥½åœ°è¿›è¡Œå»ºæ¨¡å’Œé¢„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959cc08",
   "metadata": {},
   "source": [
    "## å¤šæ­¥é¢„æµ‹æ–¹æ³•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e5343",
   "metadata": {},
   "source": [
    "åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ï¼Œå¤šæ­¥é¢„æµ‹æŒ‡çš„æ˜¯é¢„æµ‹å¤šä¸ªæœªæ¥æ—¶åˆ»çš„å€¼ã€‚å¤šæ­¥é¢„æµ‹çš„æ–¹æ³•ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ï¼š\n",
    "\n",
    "1. ç›´æ¥æ–¹æ³•ï¼ˆDirect Methodï¼‰\n",
    "æ¯ä¸ªæœªæ¥æ—¶åˆ»å•ç‹¬è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œå³é¢„æµ‹ç¬¬ ğ‘¡+1æ—¶åˆ»çš„ä¸€ä¸ªæ¨¡å‹ã€é¢„æµ‹ç¬¬ t+2 æ—¶åˆ»çš„å¦ä¸€ä¸ªæ¨¡å‹ï¼Œä¾æ­¤ç±»æ¨ã€‚  \n",
    "ä¼˜ç‚¹ï¼šæ¯ä¸ªæ¨¡å‹ä¸“é—¨é’ˆå¯¹ä¸€ä¸ªç‰¹å®šçš„æœªæ¥æ—¶åˆ»è¿›è¡Œä¼˜åŒ–ï¼Œå¯èƒ½è·å¾—è¾ƒé«˜çš„é¢„æµ‹ç²¾åº¦ã€‚  \n",
    "ç¼ºç‚¹ï¼šéœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œå½“é¢„æµ‹æ­¥æ•°è¾ƒå¤šæ—¶è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œä¸”æ¨¡å‹æ•°é‡éšæ­¥æ•°å¢åŠ ã€‚  \n",
    "2. é€’å½’æ–¹æ³•ï¼ˆIterative Methodï¼‰\n",
    "ä½¿ç”¨ä¸€ä¸ªå•æ­¥é¢„æµ‹çš„æ¨¡å‹åå¤è¿­ä»£ï¼Œå…ˆé¢„æµ‹ç¬¬ t+1 æ—¶åˆ»çš„å€¼ï¼Œç„¶åå°†å…¶ä½œä¸ºè¾“å…¥é¢„æµ‹ç¬¬ t+2 æ—¶åˆ»ï¼Œä»¥æ­¤ç±»æ¨ã€‚  \n",
    "ä¼˜ç‚¹ï¼šåªéœ€è¦è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œæ–¹æ³•ç®€å•ä¸”ç›´è§‚ã€‚  \n",
    "ç¼ºç‚¹ï¼šé¢„æµ‹è¯¯å·®ä¼šé€æ­¥ç´¯ç§¯ï¼Œå¯¼è‡´é¢„æµ‹ç²¾åº¦ä¸‹é™ã€‚  \n",
    "3. ç›´æ¥é€’å½’æ··åˆæ–¹æ³•ï¼ˆDirRec Methodï¼‰\n",
    "ç»“åˆäº†ç›´æ¥æ–¹æ³•å’Œé€’å½’æ–¹æ³•ï¼Œé¦–å…ˆé¢„æµ‹æŸä¸ªæœªæ¥æ—¶åˆ»ï¼Œç„¶åå°†é¢„æµ‹ç»“æœä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ç‰¹å¾ã€‚  \n",
    "è¿™ç§æ–¹æ³•æ—¢ä¿æŒäº†ç›´æ¥æ–¹æ³•çš„çµæ´»æ€§ï¼Œåˆèƒ½åˆ©ç”¨é€’å½’æ–¹æ³•çš„è¿ç»­æ€§ï¼Œé€‚ç”¨äºç‰¹å¾è¾ƒå°‘çš„åœºæ™¯ã€‚  \n",
    "4. å¤šè¾“å‡ºæ–¹æ³•ï¼ˆMulti-Output Methodï¼‰\n",
    "è®­ç»ƒä¸€ä¸ªå¤šè¾“å‡ºçš„æ¨¡å‹ï¼Œä¸€æ¬¡æ€§é¢„æµ‹å¤šä¸ªæœªæ¥æ—¶åˆ»çš„å€¼ã€‚  \n",
    "ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚XGBoost/LightGBMï¼‰æ¥é¢„æµ‹ä¸€ä¸ªåŒ…å«å¤šä¸ªæœªæ¥æ—¶åˆ»å€¼çš„å‘é‡ã€‚  \n",
    "ä¼˜ç‚¹ï¼šæ¨¡å‹åªéœ€è¦è®­ç»ƒä¸€æ¬¡ï¼Œä¸”èƒ½è€ƒè™‘å¤šä¸ªæœªæ¥æ—¶åˆ»ä¹‹é—´çš„ç›¸å…³æ€§ã€‚  \n",
    "ç¼ºç‚¹ï¼šå¯¹äºé•¿æ—¶é—´è·¨åº¦çš„é¢„æµ‹ï¼Œæ¨¡å‹å¤æ‚åº¦è¾ƒé«˜ï¼Œä¸”éš¾ä»¥ä¿è¯æ‰€æœ‰è¾“å‡ºçš„å‡†ç¡®æ€§ã€‚  \n",
    "5. çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆState Space Modelsï¼‰\n",
    "åŸºäºçŠ¶æ€ç©ºé—´çš„æ–¹æ³•ï¼ˆå¦‚å¡å°”æ›¼æ»¤æ³¢ã€ç²’å­æ»¤æ³¢ï¼‰æ¥åšå¤šæ­¥é¢„æµ‹ï¼Œé€šè¿‡æ„å»ºçŠ¶æ€è½¬ç§»æ¨¡å‹è¿­ä»£é¢„æµ‹æœªæ¥æ—¶åˆ»çš„çŠ¶æ€ã€‚  \n",
    "é€‚ç”¨äºåŒ…å«å™ªå£°å’Œä¸ç¡®å®šæ€§çš„æ—¶é—´åºåˆ—æ•°æ®ã€‚  \n",
    "6. ç»„åˆæ–¹æ³•ï¼ˆEnsemble Methodsï¼‰\n",
    "å°†å¤šç§æ–¹æ³•ç»“åˆä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨é€’å½’æ–¹æ³•å¾—åˆ°åˆæ­¥é¢„æµ‹ï¼Œå†ä½¿ç”¨ç›´æ¥æ–¹æ³•å¯¹å…¶è¿›è¡Œè°ƒæ•´ã€‚  \n",
    "å¯ä»¥åˆ©ç”¨ä¸åŒæ–¹æ³•çš„ä¼˜ç‚¹ï¼Œå‡å°‘å•ä¸€æ–¹æ³•çš„ç¼ºç‚¹ã€‚  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c347a0",
   "metadata": {},
   "source": [
    "# åŸºäºXGBoostçš„æ—¶é—´åºåˆ—é¢„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a70cd2",
   "metadata": {},
   "source": [
    "## å¤šè¾“å…¥å•è¾“å‡ºå•æ­¥é¢„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1c857",
   "metadata": {},
   "source": [
    "### æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e444a834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:19:02.552254Z",
     "start_time": "2024-10-17T09:19:02.541595Z"
    }
   },
   "outputs": [],
   "source": [
    "# è¯»å–æ•°æ®\n",
    "def loader(data_path=None, data=None, time_col=None, datetime=None, freq=None):\n",
    "    \"\"\"\n",
    "    è¯»å–æ•°æ®ï¼Œå¹¶å¯¹è¾“å…¥æ•°æ®æ—¶é—´åˆ—è¿›è¡Œå¤„ç†\n",
    "\n",
    "    å‚æ•°è¯´æ˜\n",
    "    ----------\n",
    "    data_path : {str}\n",
    "        è¾“å…¥æ•°æ®åœ°å€ï¼Œå¦‚æœä¸ºç©ºï¼Œè¯»å–å·²æœ‰æ•°æ®\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        è¾“å…¥æ•°æ®ï¼Œå¦‚æœéœ€è¯»å–æœ¬åœ°æ•°æ®ï¼Œå°†è¯¥å€¼ç½®ç©ºï¼Œå¦åˆ™ä¼ å…¥å·²æœ‰æ•°æ®\n",
    "    time_col : {str}\n",
    "        è¾“å…¥æ•°æ®çš„æ—¶é—´åˆ—ï¼Œå¦‚æœæ²¡æœ‰æ—¶é—´åˆ—ï¼Œç”Ÿæˆæ—¶é—´æˆ³èŒƒå›´ï¼Œæˆ–è€…ç”Ÿæˆå›ºå®šé¢‘ç‡çš„æ—¶é—´æˆ³æ•°æ®\n",
    "    datetime : {str} \n",
    "        æ—¶é—´åˆ—å¼€å§‹æ—¶é—´ï¼Œå¦‚æœtime_colä¸ºç©ºï¼Œéœ€å¡«å…¥æ­¤é¡¹ï¼Œæ ¼å¼ä¸º%Y-%m-%d %H:%M:%S\n",
    "    freq : {int}\n",
    "        æ—¶é—´åºåˆ—é¢‘ç‡ï¼Œå•ä½ä¸ºç§’\n",
    "\n",
    "    è¿”å›å€¼\n",
    "    -------\n",
    "    data : {DataFrame} of shape (n_samples, n_features)\n",
    "        ç»è¿‡æ—¶é—´åºåˆ—å¤„ç†åçš„æ•°æ®\n",
    "    \"\"\"\n",
    "    # è¯»å–åŸå§‹æ•°æ®\n",
    "    if data_path == None:\n",
    "        if data.empty is True:\n",
    "            raise ValueError(\"data is not exist!\")\n",
    "        else:\n",
    "            data = data\n",
    "    else:\n",
    "        data = pd.read_csv(data_path)\n",
    "    \n",
    "    # æ—¶é—´åˆ—å¤„ç†\n",
    "    if time_col == None:\n",
    "        # ç­›é€‰è¾“å…¥é¢‘ç‡\n",
    "        re_1 = re.findall('[0-9]', freq)\n",
    "        re_2 = re.findall('[a-z]', freq)\n",
    "        # è¯†åˆ«æ•°å­—é¢‘ç‡\n",
    "        if len(re_1) == 0:\n",
    "            nums = 1\n",
    "        else:\n",
    "            nums = int(''.join(re_1))\n",
    "        # è¯†åˆ«é¢‘ç‡\n",
    "        fr = re_2[0]\n",
    "        # ç”Ÿæˆæ—¶é—´é—´éš”\n",
    "        if fr == 's':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(seconds=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 't':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(minutes=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'h':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(hours=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        elif fr == 'd':\n",
    "            time_index = pd.date_range(start=pd.to_datetime(datetime),\n",
    "                                       end=pd.to_datetime(datetime) +\n",
    "                                       timedelta(days=(data.shape[0] - 1)*nums),\n",
    "                                       freq=freq)\n",
    "        full_data = pd.DataFrame(data=data.values,\n",
    "                                 index=pd.to_datetime(time_index, unit=freq),\n",
    "                                 columns=data.columns)\n",
    "    else:\n",
    "        columns = [i for i in data.columns if i != time_col] # å»é™¤æ—¶é—´åˆ—\n",
    "        full_data = pd.DataFrame(data=data.drop([time_col], axis=1).values,\n",
    "                                 index=pd.to_datetime(data[time_col].values),\n",
    "                                 columns=columns)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "729bada7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:01:27.609455Z",
     "start_time": "2024-10-17T10:01:27.562117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2,698.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>2,558.00</td>\n",
       "      <td>32.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>2,444.00</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2,402.00</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2,403.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>4,012.00</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>3,856.00</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>3,671.00</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>3,499.00</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>3,345.00</td>\n",
       "      <td>15.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        load  temp\n",
       "2012-01-01 00:00:00 2,698.00 32.00\n",
       "2012-01-01 01:00:00 2,558.00 32.67\n",
       "2012-01-01 02:00:00 2,444.00 30.00\n",
       "2012-01-01 03:00:00 2,402.00 31.00\n",
       "2012-01-01 04:00:00 2,403.00 32.00\n",
       "...                      ...   ...\n",
       "2014-12-31 19:00:00 4,012.00 18.00\n",
       "2014-12-31 20:00:00 3,856.00 16.67\n",
       "2014-12-31 21:00:00 3,671.00 17.00\n",
       "2014-12-31 22:00:00 3,499.00 15.33\n",
       "2014-12-31 23:00:00 3,345.00 15.33\n",
       "\n",
       "[26304 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../outputs/datasets/energy.csv\"\n",
    "ts_data = loader(data_path=data_path, data=None, time_col='time')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05fbce",
   "metadata": {},
   "source": [
    "### ç‰¹å¾æ„é€ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61d5cb9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:01:29.713306Z",
     "start_time": "2024-10-17T10:01:29.704896Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ—¶é—´ç‰¹å¾æ„é€ ï¼ŒåŒ…å«æ—¥æœŸæ—¶é—´ç‰¹å¾ã€æ»åç‰¹å¾å’Œçª—å£ç‰¹å¾ã€æ»šåŠ¨çª—å£ç»Ÿè®¡ä¿¡æ¯\n",
    "def generated_features(data: pd.DataFrame, date_type: List[str], seq_len: int,\n",
    "                       window_type: List[str], freq: str):\n",
    "    \"\"\"\n",
    "    æ—¶é—´ç‰¹å¾æ„é€ \n",
    "\n",
    "    å‚æ•°è¯´æ˜\n",
    "    ----------\n",
    "    data : {DataFrame}\n",
    "        è¾“å…¥æ•°æ®\n",
    "    date_type : {List[str]}\n",
    "        æ—¥æœŸç‰¹å¾ï¼ŒåŒ…å«year,month,day,hour,minute,second,weekç­‰\n",
    "    seq_len : {int}\n",
    "        seq_lenè¡¨ç¤ºæœ€å¤šåç§»å‡ ä½\n",
    "    window_type : {int} \n",
    "        æ»‘åŠ¨çª—å£ç‰¹å¾ï¼ŒåŒ…å«min, mean, maxç­‰\n",
    "    freq : {str} \n",
    "        æ»åé¢‘ç‡ï¼ŒåŒ…å«'h','t','s'ç­‰\n",
    "\n",
    "    è¿”å›å€¼\n",
    "    -------\n",
    "    data : {DataFrame}\n",
    "        è¾“å‡ºæ•°æ®\n",
    "    \"\"\"\n",
    "    # æ»åç‰¹å¾å’Œçª—å£ç‰¹å¾\n",
    "    for var in data.columns:\n",
    "        for t in range(1, seq_len + 1):\n",
    "            data[var + \"_lag\" + str(t)] = data[var].shift(t, freq=freq)\n",
    "\n",
    "        # æ»šåŠ¨çª—å£ç»Ÿè®¡ä¿¡æ¯\n",
    "        shifted = data[var].shift(1)\n",
    "        window = shifted.rolling(window=seq_len)\n",
    "        for stats in window_type:\n",
    "            data[var + \"_\" + stats] = eval(f\"window.{stats}()\")\n",
    "\n",
    "    # æ—¥æœŸæ—¶é—´ç‰¹å¾\n",
    "    for types in date_type:\n",
    "        if types == 'day':\n",
    "            data[types] = [data.index[i].day for i in range(len(data))]\n",
    "        elif types == 'hour':\n",
    "            data[types] = [data.index[i].hour for i in range(len(data))]\n",
    "        elif types == 'minute':\n",
    "            data[types] = [data.index[i].minute for i in range(len(data))]\n",
    "        elif types == 'second':\n",
    "            data[types] = [data.index[i].second for i in range(len(data))]\n",
    "        elif types == 'month':\n",
    "            data[types] = [data.index[i].month for i in range(len(data))]\n",
    "\n",
    "    # åˆ é™¤Noneæ•°æ®\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2a67c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:01:31.152926Z",
     "start_time": "2024-10-17T10:01:30.592913Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ„é€ å‚æ•°å­—å…¸\n",
    "params1 = {\n",
    "    \"data\": ts_data,\n",
    "    \"date_type\": ['day', 'hour', 'minute', 'second'],\n",
    "    \"seq_len\": 6,\n",
    "    \"window_type\": [\"min\", \"mean\", \"max\"],\n",
    "    \"freq\": 'h',\n",
    "}\n",
    "\n",
    "#å‡½æ•°ä¼ å‚\n",
    "data = generated_features(**params1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873b08c",
   "metadata": {},
   "source": [
    "### æ•°æ®åˆ’åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a936d729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:01:32.587770Z",
     "start_time": "2024-10-17T10:01:32.575595Z"
    }
   },
   "outputs": [],
   "source": [
    "# åŒ…å«æ—¶é—´ç»´åº¦çš„æ•°æ®é›†åˆ’åˆ†\n",
    "def divider(df, train_ratio, valid_ratio, x_feature_list, y_feature_list, scaler_path):\n",
    "    \"\"\"\n",
    "    è¯»å–æ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œåˆ’åˆ†\n",
    "\n",
    "    å‚æ•°è¯´æ˜\n",
    "    ----------\n",
    "    df : {DataFrame} of shape (n_samples, n_features)\n",
    "        è¾“å…¥æ•°æ®\n",
    "    train_ratio : {float}\n",
    "        ç”¨äºè®­ç»ƒçš„æ•°æ®é›†å æ¯”:å°†æ•°æ®æŒ‰ç…§ä¸€å®šæ¯”ä¾‹è¿›è¡Œåˆ‡åˆ†ï¼Œå–å€¼èŒƒå›´ä¸º(0,1)\n",
    "    valid_ratio : {float}\n",
    "        ç”¨äºéªŒè¯çš„æ•°æ®é›†å æ¯”:å°†æ•°æ®æŒ‰ç…§ä¸€å®šæ¯”ä¾‹è¿›è¡Œåˆ‡åˆ†ï¼Œå–å€¼èŒƒå›´ä¸º(0,1)\n",
    "    x_feature_list : {list[str]} \n",
    "        è®­ç»ƒç‰¹å¾åˆ—ï¼Œä¸åŒ…å«æ—¶é—´åˆ—\n",
    "    y_feature_list : {list[str]} \n",
    "        ç›®æ ‡ç‰¹å¾åˆ—ï¼Œä¸åŒ…å«æ—¶é—´åˆ—\n",
    "    scaler_path : {str} \n",
    "        æ•°æ®å½’ä¸€åŒ–æ¨¡å‹ä¿å­˜åœ°å€\n",
    "\n",
    "    è¿”å›å€¼\n",
    "    -------\n",
    "    x_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        è®­ç»ƒç‰¹å¾åˆ—å½’ä¸€åŒ–å™¨\n",
    "    y_scaler : {sklearn.preprocessing.MinMaxScaler}\n",
    "        ç›®æ ‡ç‰¹å¾åˆ—å½’ä¸€åŒ–å™¨\n",
    "    train : {list[DataFrame]}\n",
    "        è®­ç»ƒç‰¹å¾æ•°æ®ï¼Œç›®æ ‡ç‰¹å¾æ•°æ®ï¼Œæ—¶é—´ç‰¹å¾æ•°æ®\n",
    "    valid : {list[DataFrame]}\n",
    "        éªŒè¯ç‰¹å¾æ•°æ®ï¼Œç›®æ ‡ç‰¹å¾æ•°æ®ï¼Œæ—¶é—´ç‰¹å¾æ•°æ®\n",
    "    test : {list[DataFrame]}\n",
    "        æµ‹è¯•ç‰¹å¾æ•°æ®ï¼Œç›®æ ‡ç‰¹å¾æ•°æ®ï¼Œæ—¶é—´ç‰¹å¾æ•°æ®\n",
    "    \"\"\"\n",
    "    #å½’ä¸€åŒ–\n",
    "    x_scaler = MinMaxScaler() # ä¿è¯æ•°æ®åŒåˆ†å¸ƒ\n",
    "    y_scaler = MinMaxScaler()\n",
    "    x_scaler = x_scaler.fit(df.copy()[x_feature_list]) \n",
    "    y_scaler = y_scaler.fit(df.copy()[y_feature_list])\n",
    "\n",
    "    # è®¾ç½®ä¿å­˜å½’ä¸€åŒ–å‚æ•°è·¯å¾„\n",
    "    if not os.path.exists(scaler_path):\n",
    "        os.makedirs(scaler_path)\n",
    "\n",
    "    # ä¿å­˜å½’ä¸€åŒ–å‚æ•°\n",
    "    joblib.dump(x_scaler, scaler_path + \"/x_scaler.pkl\")\n",
    "    joblib.dump(y_scaler, scaler_path + \"/y_scaler.pkl\")\n",
    "\n",
    "    #æµ‹è¯•é›†\n",
    "    train = df.copy().iloc[:int(df.shape[0]*train_ratio), :][x_feature_list]\n",
    "    train[x_feature_list] = x_scaler.transform(train)\n",
    "    xtr = train.values.astype('float32')\n",
    "    ytr = df.copy().iloc[:int(df.shape[0]*train_ratio), :][y_feature_list]\n",
    "    ytr[y_feature_list] = y_scaler.transform(ytr)\n",
    "    ytr = ytr.values.astype('float32')\n",
    "    train = [xtr, ytr]\n",
    "\n",
    "    #éªŒè¯é›†\n",
    "    valid = df.copy().iloc[int(df.shape[0]*train_ratio): int(df.shape[0]*(train_ratio+valid_ratio)), :][x_feature_list]\n",
    "    valid[x_feature_list] = x_scaler.transform(valid)\n",
    "    xva = valid.values.astype('float32')\n",
    "    yva = df.copy().iloc[int(df.shape[0]*train_ratio): int(df.shape[0]*(train_ratio+valid_ratio)), :][y_feature_list]\n",
    "    yva[y_feature_list] = y_scaler.transform(yva)\n",
    "    yva = yva.values.astype('float32')\n",
    "    valid = [xva, yva]\n",
    "\n",
    "    #æµ‹è¯•é›†\n",
    "    if train_ratio + valid_ratio != 1:\n",
    "        test = df.copy().iloc[int(df.shape[0]*(train_ratio+valid_ratio)):, :][x_feature_list]\n",
    "        test[x_feature_list] = x_scaler.transform(test)\n",
    "        xte = test.values.astype('float32')\n",
    "        yte = df.copy().iloc[int(df.shape[0]*(train_ratio+valid_ratio)):, :][y_feature_list]\n",
    "        yte[y_feature_list] = y_scaler.transform(yte)\n",
    "        yte = yte.values.astype('float32')\n",
    "        test = [xte, yte]\n",
    "    else:\n",
    "        test = [np.array(0), np.array(0)]\n",
    "    \n",
    "    return x_scaler, y_scaler, train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c25e6206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:01:33.920844Z",
     "start_time": "2024-10-17T10:01:33.819320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (21038, 23) y_train shape: (21038, 1)\n",
      "x_valid shape: (2630, 23) y_valid shape: (2630, 1)\n",
      "x_test shape: (2630, 23) y_test shape: (2630, 1)\n"
     ]
    }
   ],
   "source": [
    "# æ„é€ å‚æ•°å­—å…¸\n",
    "params2 = {\n",
    "    \"df\": data,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"valid_ratio\": 0.1,\n",
    "    \"x_feature_list\": list(set(data.columns)-set(['temp'])),\n",
    "    \"y_feature_list\": ['temp'],\n",
    "    \"scaler_path\": '../outputs/scalers/XGBoost'\n",
    "}\n",
    "\n",
    "#å‡½æ•°ä¼ å‚\n",
    "x_scaler, y_scaler, train_data, valid_data, test_data = divider(**params2)\n",
    "x_train, y_train = train_data[0], train_data[1]\n",
    "x_test, y_test = test_data[0], test_data[1]\n",
    "print(\"x_train shape: {0} y_train shape: {1}\".format(train_data[0].shape, train_data[1].shape))\n",
    "print(\"x_valid shape: {0} y_valid shape: {1}\".format(valid_data[0].shape, valid_data[1].shape))\n",
    "print(\"x_test shape: {0} y_test shape: {1}\".format(test_data[0].shape, test_data[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283f132",
   "metadata": {},
   "source": [
    "### æ¨¡å‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "be472ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:26:47.297106Z",
     "start_time": "2024-10-17T10:26:47.292549Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_args, model_args):\n",
    "    # å‚æ•°é…ç½®\n",
    "    model_path = train_args['model_path']\n",
    "    \n",
    "    # æ¨¡å‹è®­ç»ƒ\n",
    "    xgb = XGBRegressor(**model_args)\n",
    "    model = xgb.fit(x_train, y_train)\n",
    "    \n",
    "    # ä¿å­˜æ¨¡å‹\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f1f35bb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:26:48.750480Z",
     "start_time": "2024-10-17T10:26:48.474272Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ„é€ å‚æ•°å­—å…¸\n",
    "params3 = {\n",
    "    \"train_args\": {\n",
    "        \"model_path\": \"../outputs/best_models/xgboost.pkl\",\n",
    "    },\n",
    "    \"model_args\": {\n",
    "        'n_estimators': 10,\n",
    "        'max_depth': 10, \n",
    "        'learning_rate': 0.1,\n",
    "        'random_state': 0,\n",
    "    },\n",
    "}\n",
    "model = train(**params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a115df",
   "metadata": {},
   "source": [
    "### æ¨¡å‹æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e73629b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:27:04.720128Z",
     "start_time": "2024-10-17T10:27:04.715430Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test):\n",
    "    prediction = model.predict(x_test)\n",
    "    # è®¡ç®—R2ï¼Œå‡æ–¹å·®\n",
    "    r2 = r2_score(y_test, prediction)\n",
    "    mse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    print(\"mse: {:.4f}\\nr2: {:.4f}\".format(mse, r2))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d888480",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:27:21.446278Z",
     "start_time": "2024-10-17T10:27:21.440004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.0444\n",
      "r2: 0.8708\n"
     ]
    }
   ],
   "source": [
    "res = test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6acc3",
   "metadata": {},
   "source": [
    "### ç»“æœåˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe538fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d83a40",
   "metadata": {},
   "source": [
    "### æ¨¡å‹é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf335fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, seq_len, scaler_path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7087fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288d946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
